{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "r5JGYS30uG5J",
        "outputId": "7e40197b-0223-4794-aff8-add11f89bd5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      customer_id  credit_score  country  gender  age  tenure    balance  \\\n",
              "0        15634602           619   France  Female   42       2       0.00   \n",
              "1        15647311           608    Spain  Female   41       1   83807.86   \n",
              "2        15619304           502   France  Female   42       8  159660.80   \n",
              "3        15701354           699   France  Female   39       1       0.00   \n",
              "4        15737888           850    Spain  Female   43       2  125510.82   \n",
              "...           ...           ...      ...     ...  ...     ...        ...   \n",
              "9995     15606229           771   France    Male   39       5       0.00   \n",
              "9996     15569892           516   France    Male   35      10   57369.61   \n",
              "9997     15584532           709   France  Female   36       7       0.00   \n",
              "9998     15682355           772  Germany    Male   42       3   75075.31   \n",
              "9999     15628319           792   France  Female   28       4  130142.79   \n",
              "\n",
              "      products_number  credit_card  active_member  estimated_salary  churn  \n",
              "0                   1            1              1         101348.88      1  \n",
              "1                   1            0              1         112542.58      0  \n",
              "2                   3            1              0         113931.57      1  \n",
              "3                   2            0              0          93826.63      0  \n",
              "4                   1            1              1          79084.10      0  \n",
              "...               ...          ...            ...               ...    ...  \n",
              "9995                2            1              0          96270.64      0  \n",
              "9996                1            1              1         101699.77      0  \n",
              "9997                1            0              1          42085.58      1  \n",
              "9998                2            1              0          92888.52      1  \n",
              "9999                1            1              0          38190.78      0  \n",
              "\n",
              "[10000 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbd05aef-5a7e-49e2-8298-2afd0d48f909\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>credit_score</th>\n",
              "      <th>country</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>tenure</th>\n",
              "      <th>balance</th>\n",
              "      <th>products_number</th>\n",
              "      <th>credit_card</th>\n",
              "      <th>active_member</th>\n",
              "      <th>estimated_salary</th>\n",
              "      <th>churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15634602</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15647311</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15619304</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15701354</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15737888</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>15606229</td>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>15569892</td>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>15584532</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>15682355</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>15628319</td>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbd05aef-5a7e-49e2-8298-2afd0d48f909')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bbd05aef-5a7e-49e2-8298-2afd0d48f909 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bbd05aef-5a7e-49e2-8298-2afd0d48f909');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = '/content/drive/MyDrive/Bank Customer Churn Prediction.csv'\n",
        "data = pd.read_csv(url, encoding = 'utf8')\n",
        "\n",
        "data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Read the dataset and display columns\n",
        "print(data.columns)\n",
        "\n",
        "# Here are some basic exploratory data analysis (EDA) :\n",
        "print(data.head())\n",
        "print(data.describe())\n",
        "print(data.info())\n",
        "\n",
        "# Here are some columns that may be useful in predicting churn:\n",
        "features = ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'credit_card', 'active_member', 'estimated_salary']\n",
        "\n",
        "# Creating train and test sets\n",
        "X = data[features]\n",
        "y = data['churn']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training machine learning model to predict churn\n",
        "# Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating model on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1 score:', f1)\n",
        "print('Confusion matrix:\\n', conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7eb1dMtzh4H",
        "outputId": "27f15542-9e87-4996-d742-a3535fea5dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['customer_id', 'credit_score', 'country', 'gender', 'age', 'tenure',\n",
            "       'balance', 'products_number', 'credit_card', 'active_member',\n",
            "       'estimated_salary', 'churn'],\n",
            "      dtype='object')\n",
            "   customer_id  credit_score country  gender  age  tenure    balance  \\\n",
            "0     15634602           619  France  Female   42       2       0.00   \n",
            "1     15647311           608   Spain  Female   41       1   83807.86   \n",
            "2     15619304           502  France  Female   42       8  159660.80   \n",
            "3     15701354           699  France  Female   39       1       0.00   \n",
            "4     15737888           850   Spain  Female   43       2  125510.82   \n",
            "\n",
            "   products_number  credit_card  active_member  estimated_salary  churn  \n",
            "0                1            1              1         101348.88      1  \n",
            "1                1            0              1         112542.58      0  \n",
            "2                3            1              0         113931.57      1  \n",
            "3                2            0              0          93826.63      0  \n",
            "4                1            1              1          79084.10      0  \n",
            "        customer_id  credit_score           age        tenure        balance  \\\n",
            "count  1.000000e+04  10000.000000  10000.000000  10000.000000   10000.000000   \n",
            "mean   1.569094e+07    650.528800     38.921800      5.012800   76485.889288   \n",
            "std    7.193619e+04     96.653299     10.487806      2.892174   62397.405202   \n",
            "min    1.556570e+07    350.000000     18.000000      0.000000       0.000000   \n",
            "25%    1.562853e+07    584.000000     32.000000      3.000000       0.000000   \n",
            "50%    1.569074e+07    652.000000     37.000000      5.000000   97198.540000   \n",
            "75%    1.575323e+07    718.000000     44.000000      7.000000  127644.240000   \n",
            "max    1.581569e+07    850.000000     92.000000     10.000000  250898.090000   \n",
            "\n",
            "       products_number  credit_card  active_member  estimated_salary  \\\n",
            "count     10000.000000  10000.00000   10000.000000      10000.000000   \n",
            "mean          1.530200      0.70550       0.515100     100090.239881   \n",
            "std           0.581654      0.45584       0.499797      57510.492818   \n",
            "min           1.000000      0.00000       0.000000         11.580000   \n",
            "25%           1.000000      0.00000       0.000000      51002.110000   \n",
            "50%           1.000000      1.00000       1.000000     100193.915000   \n",
            "75%           2.000000      1.00000       1.000000     149388.247500   \n",
            "max           4.000000      1.00000       1.000000     199992.480000   \n",
            "\n",
            "              churn  \n",
            "count  10000.000000  \n",
            "mean       0.203700  \n",
            "std        0.402769  \n",
            "min        0.000000  \n",
            "25%        0.000000  \n",
            "50%        0.000000  \n",
            "75%        0.000000  \n",
            "max        1.000000  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 12 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   customer_id       10000 non-null  int64  \n",
            " 1   credit_score      10000 non-null  int64  \n",
            " 2   country           10000 non-null  object \n",
            " 3   gender            10000 non-null  object \n",
            " 4   age               10000 non-null  int64  \n",
            " 5   tenure            10000 non-null  int64  \n",
            " 6   balance           10000 non-null  float64\n",
            " 7   products_number   10000 non-null  int64  \n",
            " 8   credit_card       10000 non-null  int64  \n",
            " 9   active_member     10000 non-null  int64  \n",
            " 10  estimated_salary  10000 non-null  float64\n",
            " 11  churn             10000 non-null  int64  \n",
            "dtypes: float64(2), int64(8), object(2)\n",
            "memory usage: 937.6+ KB\n",
            "None\n",
            "Accuracy: 0.8585\n",
            "Precision: 0.7455357142857143\n",
            "Recall: 0.42493638676844786\n",
            "F1 score: 0.5413290113452188\n",
            "Confusion matrix:\n",
            " [[1550   57]\n",
            " [ 226  167]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Training a machine learning model to predict churn\n",
        "# Logistic Regression\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate your model on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1 score:', f1)\n",
        "print('Confusion matrix:\\n', conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5hQmMGX08S5",
        "outputId": "3dc215f9-a819-4354-85ae-f85c101a7a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8005\n",
            "Precision: 0.45161290322580644\n",
            "Recall: 0.07124681933842239\n",
            "F1 score: 0.12307692307692307\n",
            "Confusion matrix:\n",
            " [[1573   34]\n",
            " [ 365   28]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHih43KQ1AlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2 - Product Sales\n",
        "\n",
        "\n",
        "1. \n",
        "The orders_items table is used to represent the items that were included in each order in the orders table. It has a many-to-many relationship with the products table, since each order can contain multiple products, and each product can be included in multiple orders. The quantity column represents the number of units of a given product that were included in a given order.\n"
      ],
      "metadata": {
        "id": "kp4x6l6h2UTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SQL query to find the average order cost per country \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "SELECT c.country, AVG(o.order_cost) AS avg_order_cost\n",
        "FROM customers c\n",
        "JOIN orders o ON c.id = o.id_customer\n",
        "GROUP BY c.country;\n",
        "```\n",
        "\n",
        "This query joins the customers and orders tables on the customer ID, and groups the results by country. The AVG function is used to calculate the average order cost for each country.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YCymWZ903Lde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SQL query to find the name of the highest price product sold to an Italian customer:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "SELECT p.name\n",
        "FROM products p\n",
        "JOIN orders_items oi ON p.id = oi.id_product\n",
        "JOIN orders o ON oi.id_order = o.id\n",
        "JOIN customers c ON o.id_customer = c.id\n",
        "WHERE c.country = 'Italy'\n",
        "ORDER BY p.price DESC\n",
        "LIMIT 1;\n",
        "```\n",
        "\n",
        "This query joins the products, orders_items, orders, and customers tables to find the highest price product sold to an Italian customer. It first filters the customers table to only include customers from Italy, then joins the orders_items table to the products table to get the name and price of each product sold. Finally, it sorts the results by price in descending order, and uses LIMIT 1 to only return the highest-priced product.\n",
        "\n"
      ],
      "metadata": {
        "id": "pNEy4zLv4GXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4**. \n",
        "\n",
        "To optimize the orders table for a high volume of queries, we could consider using indexing. For example, you could create an index on the id_customer column in the orders table, which would make it faster to look up all orders for a given customer. we could also create indexes on other frequently queried columns, such as order_cost or order_date.\n",
        "\n",
        "there are a few other techniques that can be used to optimize the orders table for a high volume of queries:\n",
        "Partitioning: This involves splitting the orders table into multiple smaller tables based on a chosen partitioning key (such as date, customer ID, or order status). This can help reduce query times by allowing queries to be executed on smaller subsets of the data.\n",
        "\n",
        "Denormalization: This involves duplicating data across tables in order to reduce the need for joins. For example, you could denormalize the orders table by including the customer name and country in each row, rather than requiring a join with the customers table for each query.\n",
        "\n",
        "Caching: This involves storing the results of frequently executed queries in memory or on disk, so that they can be served quickly without needing to hit the database."
      ],
      "metadata": {
        "id": "WXzJEIcq4f-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5**.\n",
        "\n",
        "if the amount of data is too big to run these queries efficiently, we would need to consider using a distributed database system or a data warehouse. These types of systems are designed to handle large volumes of data and can parallelize queries across multiple nodes to improve performance. we may also need to consider using more specialized database technologies, such as columnar databases or NoSQL databases, depending on the specific requirements of your queries.\n",
        "\n",
        "When dealing with very large amounts of data, traditional relational databases may not be sufficient to handle the volume and complexity of the data. In this case, there are a few options for managing the data:\n",
        "Distributed databases: These are databases that are designed to scale horizontally across multiple nodes, allowing them to handle large volumes of data and traffic. Examples of distributed databases include Apache Cassandra and Amazon DynamoDB.\n",
        "\n",
        "Data warehouses: These are specialized databases that are designed to handle large volumes of structured data, typically for business intelligence or reporting purposes. They often include features such as columnar storage, parallel processing, and advanced query optimization. Examples of data warehouses include Amazon Redshift and Google BigQuery.\n",
        "\n",
        "NoSQL databases: These are databases that are designed to handle unstructured or semi-structured data, such as JSON or XML documents. They are often used in applications such as web and mobile apps, where data is generated and consumed in a highly distributed and heterogeneous fashion. Examples of NoSQL databases include MongoDB and Apache CouchDB."
      ],
      "metadata": {
        "id": "8MCNs9Mz6KxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n"
      ],
      "metadata": {
        "id": "wlqYTEe_yxTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MOax2j2cyrv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3 - Machine Translation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **1**.\n",
        "Designing a data pipeline for a Machine Translation system involves several key steps:\n",
        "Data collection: This involves sourcing parallel data (i.e. text in two or more languages) that can be used to train and evaluate the machine translation model. Sources of parallel data include publicly available corpora, websites with multilingual content, and human translators.\n",
        "\n",
        "Data preprocessing: This involves cleaning and formatting the raw data to make it suitable for training the machine translation model. This includes tasks such as tokenization, sentence splitting, and language identification.\n",
        "\n",
        "Model training: This involves training the machine translation model using the preprocessed parallel data. Popular machine translation models include sequence-to-sequence models, transformer models, and neural machine translation models.\n",
        "\n",
        "Model evaluation: This involves evaluating the performance of the trained machine translation model using metrics such as BLEU, METEOR, and TER. This helps identify areas where the model may be making errors or performing poorly, and can inform decisions about further training or model tuning.\n",
        "\n",
        "Model deployment: This involves deploying the trained machine translation model in a production environment, where it can be used to translate new input text.\n",
        "\n",
        "Some of the main challenges involved in designing a data pipeline for a Machine Translation system include:\n",
        "\n",
        "Sourcing high-quality parallel data in the desired languages\n",
        "Preprocessing the data to ensure that it is suitable for training the model\n",
        "Choosing an appropriate machine translation model architecture and tuning its parameters\n",
        "Ensuring that the deployed system is fast and reliable, and that it can handle the volume and variety of input text that it may encounter in production.\n",
        "\n",
        "---\n",
        "\n",
        "### **2**.\n",
        "Collecting new and good quality data from the web for machine translation training can be a challenging task. Some strategies that can be used include:\n",
        "Scraping multilingual websites: Websites that contain content in multiple languages can be scraped to collect parallel data for machine translation training. This can be done using tools such as BeautifulSoup or Scrapy.\n",
        "\n",
        "Collaborating with human translators: Professional translators can be engaged to create new parallel data specifically for machine translation training. This can be done through crowdsourcing platforms such as Amazon Mechanical Turk or specialized translation agencies.\n",
        "\n",
        "Using existing translation memories: Translation memories are databases of previously translated texts that can be leveraged for machine translation training. Many translation agencies and language service providers have translation memories that can be licensed or accessed for free.\n",
        "\n",
        "Regardless of the approach used, it's important to ensure that the collected data is of high quality and representative of the types of input text that the machine translation system will encounter in production.\n",
        "\n",
        "---\n",
        "\n",
        "### **3**.\n",
        "To monitor the quality of a machine translation system using post-editing by professional translators, the following steps can be taken:\n",
        "Collect a sample of output translations generated by the machine translation system\n",
        "Have professional translators review and edit the output translations to improve their quality\n",
        "Compare the post-edited translations to the original input text, as well as to the output generated by the machine translation system, to identify areas where the system is making errors or producing poor-quality translations\n",
        "Use this feedback to refine and improve the machine translation model and its training data, with the goal of reducing the need for post-editing in the future.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OLMgR9VD8Uuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fXZ2clZTyHMS"
      }
    }
  ]
}